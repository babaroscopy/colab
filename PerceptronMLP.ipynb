{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PerceptronMLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babaroscopy/colab/blob/main/PerceptronMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfoRfHAQrcDJ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "# Custom activation function\n",
        "#from keras.layers import Activation\n",
        "#from keras.utils.generic_utils import get_custom_objects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Bg-esr-qRa"
      },
      "source": [
        "@tf.function\n",
        "def stepy(x): # user-defined step function, note: not working in sgd bcz of derivative not exist. It needs custom optimizer\n",
        "    if x > 0.0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5MYXeeTr11G"
      },
      "source": [
        "#Prepare dataset\n",
        "#dataset=np.random.randint(1,5,[10,3],dtype=np.int32)\n",
        "#dataset=np.random.rand(10,3)\n",
        "x_train=np.array([[0, 0],[0, 1],[1, 0],[1, 1]])\n",
        "y_train=np.array([0, 1, 1, 1])\n",
        "x_test=np.array([[0, 0],[0, 1],[1, 0],[1, 1]])\n",
        "y_test=np.array([0, 1, 1, 1])\n",
        "\n",
        "# x_train=np.array([[0, 0],[0, 1],[1, 0],[1, 1]])\n",
        "# y_train=np.array([0, 1, 1, 0])\n",
        "# x_test=np.array([[0, 0],[0, 1],[1, 0],[1, 1]])\n",
        "# y_test=np.array([0, 1, 1, 0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QAwbGecnUJR"
      },
      "source": [
        "#####Delta rule (gradient descent) implementation with a single layer output neuron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-84j9njNtzps"
      },
      "source": [
        "#Model construction (model type, inputs, layers, weight initialization, activation function)\n",
        "#Layers types(dense, dropout, merge)\n",
        "#Weight init(uniform(0-0.05), normal(0,0.05), zero)\n",
        "#Activation (linear(default), relu, sigmoid, tanh, softmax)\n",
        "\n",
        "model_delta = Sequential()\n",
        "model_delta.add(Input(shape=(2,)))\n",
        "model_delta.add(Dense(1, activation='linear', kernel_initializer='random_uniform', bias_initializer='zero'))\n",
        "#model_delta.add(Dense(1, input_dim=3, activation='linear', kernel_initializer='random_uniform', bias_initializer='zero'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wac04OCguwbW"
      },
      "source": [
        "#Model compilation (optimizer, loss funciton, metrics(performance))\n",
        "#optimizer(sgd, RMSprop, Adam), loss(mse,binary_crossentropy,categorical_crossentropy),metrics(accuracy)\n",
        "model_delta.compile(optimizer='sgd', loss='mse', metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7od6ptKlwQBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd35929-c790-4dcf-8bf3-cf47fc507f3b"
      },
      "source": [
        "#Model training\n",
        "\n",
        "model_delta.fit(x_train, y_train, epochs=10, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.2500\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f199ee43190>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-6l8DgBwXZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8924f7a1-c0a7-4caf-e0f5-67b64217b356"
      },
      "source": [
        "#Model evaluation and prediction\n",
        "#model.evaluate(),model.predict(),model.predict_classes(),model.predict_proba()\n",
        "\n",
        "loss, accuracy = model_delta.evaluate(x_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n",
        "predictions = model_delta.predict(x_test)\n",
        "rounded = [round(x[0]) for x in predictions]\n",
        "predictions, rounded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 213ms/step - loss: 0.1339 - accuracy: 1.0000\n",
            "Accuracy: 100.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.34060207],\n",
              "        [0.57359654],\n",
              "        [0.55904067],\n",
              "        [0.7920351 ]], dtype=float32), [0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zlapoRouz1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831be6ff-2f02-444e-b609-be0f1931a97e"
      },
      "source": [
        "#Model summary\n",
        "#model.summary(),model.get_config(),\n",
        "\n",
        "model_delta.summary()\n",
        "model_delta.get_config()\n",
        "model_delta.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.21843857],\n",
              "        [0.23299447]], dtype=float32), array([0.34060207], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5hzp9Z6qqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847b596f-3737-4250-abd0-431555cf0601"
      },
      "source": [
        "########## MLP Backporpagation\n",
        "x2_train=np.random.rand(10,3)\n",
        "y2_train=np.array([0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n",
        "x2_test=np.random.rand(5,3)\n",
        "y2_test=np.array([1, 1, 1, 0, 1]),\n",
        "\n",
        "model_mlp = Sequential([\n",
        "        Dense(units=2, input_shape=(3,), activation='sigmoid', kernel_initializer='random_uniform', bias_initializer='random_uniform'),\n",
        "        Dense(units=1, activation='sigmoid', kernel_initializer='random_uniform', bias_initializer='random_uniform')\n",
        "])\n",
        "            \n",
        "opt = keras.optimizers.SGD(learning_rate=0.1)\n",
        "model_mlp.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "history = model_mlp.fit(x2_train, y2_train, batch_size=1, epochs=100)\n",
        "# es = EarlyStopping(monitor='accuracy', mode='max', min_delta=1) #Early stopping criteria (Accuracy 100%)\n",
        "# history = model_mlp.fit(x2_train, y2_train, batch_size=1, epochs=100, verbose=2, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.6000\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6000\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6000\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6000\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6000\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.6000\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.6000\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.6000\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.6000\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.6000\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFEmMtDTLOck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "ec8bc98a-3ae6-4f0c-ec3e-5b79bc236bb5"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40X21DeX8ETE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b127eb5b-16f9-43b6-974e-b41dfec4f59d"
      },
      "source": [
        "loss, accuracy = model_mlp.evaluate(x2_test, y2_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n",
        "predictions = model_mlp.predict(x2_test)\n",
        "rounded = [round(x[0]) for x in predictions]\n",
        "predictions, rounded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step - loss: 0.1992 - accuracy: 0.8000\n",
            "Accuracy: 80.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.60214764],\n",
              "        [0.6014253 ],\n",
              "        [0.60218716],\n",
              "        [0.6017938 ],\n",
              "        [0.60225546]], dtype=float32), [1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}